{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1fd9fdf",
   "metadata": {},
   "source": [
    "## üìã Project Requirements Checklist\n",
    "\n",
    "‚úÖ **4.1 Task Selection**: Classification task justified by categorical labels  \n",
    "‚úÖ **4.2 Data Preparation**: Train/test split with preprocessing  \n",
    "‚úÖ **4.3 Architecture & Training**: ResNet50 with training diagnosis  \n",
    "‚úÖ **4.4 Model Evaluation**: Comprehensive metrics on test set  \n",
    "\n",
    "**Dataset**: Alzheimer's 4-class MRI  \n",
    "**Task**: Multi-class Image Classification  \n",
    "**Model**: ResNet50 (Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40dcb424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Using Apple Silicon GPU (MPS)\n",
      "‚úì Results: ../../Results/MRI_Classification\n"
     ]
    }
   ],
   "source": [
    "# 1. SETUP\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Device\n",
    "# Device configuration - Apple Silicon M3 GPU support\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(f\"‚úì Using Apple Silicon GPU (MPS)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"‚úì Using NVIDIA GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"‚ö† Using CPU (slower training)\")\n",
    "\n",
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = Path(\"../..\")  # Go up to FinalProject root from scripts/Part_4/\n",
    "DATA_DIR = PROJECT_ROOT / \"Data\" / \"Alzheimer_MRI\"\n",
    "RESULTS_DIR = PROJECT_ROOT / \"Results\" / \"MRI_Classification\"\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"‚úì Results: {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "gpu_verification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "GPU/DEVICE CONFIGURATION\n",
      "======================================================================\n",
      "PyTorch version: 2.9.1\n",
      "Device: mps\n",
      "Device type: mps\n",
      "\n",
      "üöÄ Apple Silicon M3 GPU is ACTIVE!\n",
      "   Training will use Metal Performance Shaders (MPS)\n",
      "   Expected speedup: 3-5x faster than CPU\n",
      "\n",
      "‚úì GPU test passed! Tensor computation successful.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# GPU Verification - Run this to confirm GPU is being used\n",
    "print(\"=\"*70)\n",
    "print(\"GPU/DEVICE CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Device type: {device.type}\")\n",
    "\n",
    "if device.type == 'mps':\n",
    "    print(\"\\nüöÄ Apple Silicon M3 GPU is ACTIVE!\")\n",
    "    print(\"   Training will use Metal Performance Shaders (MPS)\")\n",
    "    print(\"   Expected speedup: 3-5x faster than CPU\")\n",
    "elif device.type == 'cuda':\n",
    "    print(f\"\\nüöÄ NVIDIA GPU is ACTIVE: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Running on CPU - training will be slower\")\n",
    "    print(\"   Consider checking your PyTorch installation for MPS support\")\n",
    "\n",
    "# Quick GPU test\n",
    "try:\n",
    "    test_tensor = torch.randn(100, 100).to(device)\n",
    "    result = test_tensor @ test_tensor.T\n",
    "    print(f\"\\n‚úì GPU test passed! Tensor computation successful.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚úó GPU test failed: {e}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211e1557",
   "metadata": {},
   "source": [
    "## **Requirement 4.1: Task Selection**\n",
    "\n",
    "Download from: https://www.kaggle.com/datasets/tourist55/alzheimers-dataset-4-class-of-images\n",
    "\n",
    "Expected structure:\n",
    "```\n",
    "Data/Alzheimer_MRI/\n",
    "‚îú‚îÄ‚îÄ train/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ MildDemented/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ ModerateDemented/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ NonDemented/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ VeryMildDemented/\n",
    "‚îî‚îÄ‚îÄ test/\n",
    "    ‚îî‚îÄ‚îÄ [same structure]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ec882f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Checking DATA_DIR: /Users/ldr0/Documents/UPM/Complex Data/FinalProject/scripts/Part_4/../../Data/Alzheimer_MRI\n",
      "\n",
      "  ‚úì Mild Dementia                  (  5002 images)\n",
      "  ‚úì Moderate Dementia              (   488 images)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Non Demented                   ( 67222 images)\n",
      "  ‚úì Very mild Dementia             ( 13725 images)\n",
      "\n",
      "======================================================================\n",
      "TASK SELECTION ANALYSIS\n",
      "======================================================================\n",
      "Dataset Type: Labeled image folders\n",
      "Classes: ['Mild Dementia', 'Moderate Dementia', 'Non Demented', 'Very mild Dementia']\n",
      "Number: 4\n",
      "\n",
      "üìä Dataset Statistics:\n",
      "  Mild Dementia            :   5002 images\n",
      "  Moderate Dementia        :    488 images\n",
      "  Non Demented             :  67222 images\n",
      "  Very mild Dementia       :  13725 images\n",
      "\n",
      "  TOTAL                    :  86437 images\n",
      "\n",
      "üéØ TASK: Multi-class Classification\n",
      "Rationale: Categorical labels ‚Üí Classification task\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify dataset\n",
    "classes = [\"Mild Dementia\", \"Moderate Dementia\", \"Non Demented\", \"Very mild Dementia\"]\n",
    "class_paths = [DATA_DIR / cls for cls in classes]\n",
    "\n",
    "print(f\"üìÅ Checking DATA_DIR: {DATA_DIR.absolute()}\\n\")\n",
    "\n",
    "all_exist = True\n",
    "for cls, cls_path in zip(classes, class_paths):\n",
    "    exists = cls_path.exists()\n",
    "    status = \"‚úì\" if exists else \"‚úó\"\n",
    "    if exists:\n",
    "        jpg_count = len(list(cls_path.glob('*.jpg')))\n",
    "        print(f\"  {status} {cls:<30} ({jpg_count:>6} images)\")\n",
    "    else:\n",
    "        print(f\"  {status} {cls:<30} (NOT FOUND)\")\n",
    "        all_exist = False\n",
    "\n",
    "print()\n",
    "\n",
    "if all_exist:\n",
    "    print(\"=\"*70)\n",
    "    print(\"TASK SELECTION ANALYSIS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Dataset Type: Labeled image folders\")\n",
    "    print(f\"Classes: {classes}\")\n",
    "    print(f\"Number: {len(classes)}\")\n",
    "    \n",
    "    # Count images per class\n",
    "    print(\"\\nüìä Dataset Statistics:\")\n",
    "    total_images = 0\n",
    "    for cls, cls_path in zip(classes, class_paths):\n",
    "        jpg_files = list(cls_path.glob('*.jpg'))\n",
    "        count = len(jpg_files)\n",
    "        total_images += count\n",
    "        print(f\"  {cls:<25}: {count:>6} images\")\n",
    "    \n",
    "    print(f\"\\n  {'TOTAL':<25}: {total_images:>6} images\")\n",
    "    print(f\"\\nüéØ TASK: Multi-class Classification\")\n",
    "    print(f\"Rationale: Categorical labels ‚Üí Classification task\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"=\"*70)\n",
    "    print(\"‚ùå DATASET NOT FOUND\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"Expected folders in:\", DATA_DIR.absolute())\n",
    "    print(\"\\nPlease check:\")\n",
    "    print(\"  1. DATA_DIR path is correct\")\n",
    "    print(\"  2. Class folders exist with correct names\")\n",
    "    print(\"  3. Folders contain .jpg files\")\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da72f0e",
   "metadata": {},
   "source": [
    "## **Requirement 4.2: Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40376c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from class folders...\n",
      "  Class: Mild Dementia             Files Found:   5002\n",
      "  Class: Moderate Dementia         Files Found:    488\n",
      "  Class: Non Demented              Files Found:  67222\n",
      "  Class: Very mild Dementia        Files Found:  13725\n",
      "\n",
      "‚úì Total images loaded: 86437\n",
      "\n",
      "Total images: 86437\n",
      "Train: 73471 (85.0%)\n",
      "Test: 12966 (15.0%)\n",
      "\n",
      "üìà DATASET STATISTICS\n",
      "======================================================================\n",
      "Class                     Train      Test       Total     \n",
      "----------------------------------------------------------------------\n",
      "Mild Dementia             4252       750        5002      \n",
      "Moderate Dementia         415        73         488       \n",
      "Non Demented              57138      10084      67222     \n",
      "Very mild Dementia        11666      2059       13725     \n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset and create train/test split\n",
    "# Load all images and labels from class folders\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "print(\"Loading images from class folders...\")\n",
    "for class_label, class_name in enumerate(classes):\n",
    "    class_dir = DATA_DIR / class_name\n",
    "    if not class_dir.exists():\n",
    "        print(f\"‚ö† Warning: Folder {class_dir} does not exist. Skipping.\")\n",
    "        continue\n",
    "    \n",
    "    files = list(class_dir.glob('*.jpg'))\n",
    "    print(f\"  Class: {class_name:<25} Files Found: {len(files):>6}\")\n",
    "    \n",
    "    for file_path in files:\n",
    "        image_paths.append(str(file_path))\n",
    "        labels.append(class_label)\n",
    "\n",
    "if len(image_paths) == 0:\n",
    "    raise ValueError(\"No images found. Check dataset folder names or file paths.\")\n",
    "\n",
    "print(f\"\\n‚úì Total images loaded: {len(image_paths)}\")\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    image_paths, labels, test_size=0.15, shuffle=True, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "print(f\"\\nTotal images: {len(image_paths)}\")\n",
    "print(f\"Train: {len(x_train)} ({100*len(x_train)/len(image_paths):.1f}%)\")\n",
    "print(f\"Test: {len(x_test)} ({100*len(x_test)/len(image_paths):.1f}%)\")\n",
    "\n",
    "# Dataset statistics\n",
    "def count_class_distribution(label_list, classes):\n",
    "    stats = {}\n",
    "    for i, cls in enumerate(classes):\n",
    "        count = label_list.count(i)\n",
    "        stats[cls] = count\n",
    "    return stats\n",
    "\n",
    "train_stats = count_class_distribution(y_train, classes)\n",
    "test_stats = count_class_distribution(y_test, classes)\n",
    "\n",
    "print(\"\\nüìà DATASET STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Class':<25} {'Train':<10} {'Test':<10} {'Total':<10}\")\n",
    "print(\"-\"*70)\n",
    "for cls in sorted(train_stats.keys()):\n",
    "    tr, te = train_stats[cls], test_stats[cls]\n",
    "    print(f\"{cls:<25} {tr:<10} {te:<10} {tr+te:<10}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "ax1.bar(train_stats.keys(), train_stats.values(), color='steelblue')\n",
    "ax1.set_title('Training Set', fontweight='bold')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax2.bar(test_stats.keys(), test_stats.values(), color='coral')\n",
    "ax2.set_title('Test Set', fontweight='bold')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / '01_distribution.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46839e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Preprocessing defined:\n",
      "  ‚Ä¢ Noise reduction: Gaussian blur\n",
      "  ‚Ä¢ Augmentation: Flip, rotate, color jitter\n",
      "  ‚Ä¢ Normalization: ImageNet statistics\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing with noise reduction\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.GaussianBlur(3, sigma=(0.1, 2.0)),  # Noise reduction\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "print(\"‚úì Preprocessing defined:\")\n",
    "print(\"  ‚Ä¢ Noise reduction: Gaussian blur\")\n",
    "print(\"  ‚Ä¢ Augmentation: Flip, rotate, color jitter\")\n",
    "print(\"  ‚Ä¢ Normalization: ImageNet statistics\")\n",
    "\n",
    "# Custom Dataset class for our data structure\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class AlzheimerDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = datasets.folder.default_loader(img_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a331335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Splits: Train=58776, Val=14695, Test=12966\n",
      "‚úì Classes: ['Mild Dementia', 'Moderate Dementia', 'Non Demented', 'Very mild Dementia']\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "# Split train into train + validation (80-20 of training data)\n",
    "train_val_paths, val_paths, train_val_labels, val_labels = train_test_split(\n",
    "    x_train, y_train, test_size=0.2, shuffle=True, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "train_dataset = AlzheimerDataset(train_val_paths, train_val_labels, transform=data_transforms['train'])\n",
    "val_dataset = AlzheimerDataset(val_paths, val_labels, transform=data_transforms['test'])\n",
    "test_dataset = AlzheimerDataset(x_test, y_test, transform=data_transforms['test'])\n",
    "\n",
    "class_names = classes\n",
    "print(f\"\\n‚úì Splits: Train={len(train_dataset)}, Val={len(val_dataset)}, Test={len(test_dataset)}\")\n",
    "print(f\"‚úì Classes: {class_names}\")\n",
    "\n",
    "# DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13015f85",
   "metadata": {},
   "source": [
    "## **Requirement 4.3: Architecture Selection & Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03d4398f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODEL ARCHITECTURE\n",
      "======================================================================\n",
      "Base: ResNet50 (ImageNet pretrained)\n",
      "Total params: 24,691,012\n",
      "Trainable: 1,182,980\n",
      "Frozen: 23,508,032\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Model definition\n",
    "class AlzheimerClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        \n",
    "        # Freeze backbone\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Custom classifier\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "model = AlzheimerClassifier(len(class_names)).to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL ARCHITECTURE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Base: ResNet50 (ImageNet pretrained)\")\n",
    "print(f\"Total params: {total_params:,}\")\n",
    "print(f\"Trainable: {trainable:,}\")\n",
    "print(f\"Frozen: {total_params-trainable:,}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "991253d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Configuration:\n",
      "  ‚Ä¢ Epochs: 25\n",
      "  ‚Ä¢ Optimizer: Adam (lr=0.001, wd=1e-4)\n",
      "  ‚Ä¢ Scheduler: ReduceLROnPlateau\n",
      "  ‚Ä¢ Early stopping: 7 epochs\n"
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=3)\n",
    "\n",
    "num_epochs = 25\n",
    "early_stop_patience = 7\n",
    "best_val_acc = 0.0\n",
    "patience_counter = 0\n",
    "\n",
    "print(\"‚úì Configuration:\")\n",
    "print(f\"  ‚Ä¢ Epochs: {num_epochs}\")\n",
    "print(f\"  ‚Ä¢ Optimizer: Adam (lr=0.001, wd=1e-4)\")\n",
    "print(f\"  ‚Ä¢ Scheduler: ReduceLROnPlateau\")\n",
    "print(f\"  ‚Ä¢ Early stopping: {early_stop_patience} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce197c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Training functions defined\n"
     ]
    }
   ],
   "source": [
    "# Training functions\n",
    "def train_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc='Train', leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "    \n",
    "    return running_loss / total, 100. * correct / total\n",
    "\n",
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc='Val', leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, preds = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return running_loss / total, 100. * correct / total, all_preds, all_labels\n",
    "\n",
    "print(\"‚úì Training functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4cf63e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRAINING\n",
      "======================================================================\n",
      "\n",
      "Epoch 1/25\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m70\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m train_loss, train_acc = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m val_loss, val_acc, _, _ = validate(model, val_loader, criterion)\n\u001b[32m     15\u001b[39m scheduler.step(val_loss)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, loader, criterion, optimizer)\u001b[39m\n\u001b[32m      5\u001b[39m correct = \u001b[32m0\u001b[39m\n\u001b[32m      6\u001b[39m total = \u001b[32m0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleave\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UPM/Complex Data/FinalProject/scripts/.venv/lib/python3.13/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UPM/Complex Data/FinalProject/scripts/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UPM/Complex Data/FinalProject/scripts/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:788\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    787\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    790\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UPM/Complex Data/FinalProject/scripts/.venv/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mAlzheimerDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     39\u001b[39m image = datasets.folder.default_loader(img_path)\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     image = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m image, label\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UPM/Complex Data/FinalProject/scripts/.venv/lib/python3.13/site-packages/torchvision/transforms/transforms.py:95\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         img = \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UPM/Complex Data/FinalProject/scripts/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UPM/Complex Data/FinalProject/scripts/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UPM/Complex Data/FinalProject/scripts/.venv/lib/python3.13/site-packages/torchvision/transforms/transforms.py:1812\u001b[39m, in \u001b[36mGaussianBlur.forward\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m   1804\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1805\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   1806\u001b[39m \u001b[33;03m    img (PIL Image or Tensor): image to be blurred.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1809\u001b[39m \u001b[33;03m    PIL Image or Tensor: Gaussian blurred image\u001b[39;00m\n\u001b[32m   1810\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1811\u001b[39m sigma = \u001b[38;5;28mself\u001b[39m.get_params(\u001b[38;5;28mself\u001b[39m.sigma[\u001b[32m0\u001b[39m], \u001b[38;5;28mself\u001b[39m.sigma[\u001b[32m1\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m1812\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgaussian_blur\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UPM/Complex Data/FinalProject/scripts/.venv/lib/python3.13/site-packages/torchvision/transforms/functional.py:1380\u001b[39m, in \u001b[36mgaussian_blur\u001b[39m\u001b[34m(img, kernel_size, sigma)\u001b[39m\n\u001b[32m   1376\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mimg should be PIL Image or Tensor. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(img)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1378\u001b[39m     t_img = pil_to_tensor(img)\n\u001b[32m-> \u001b[39m\u001b[32m1380\u001b[39m output = \u001b[43mF_t\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgaussian_blur\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch.Tensor):\n\u001b[32m   1383\u001b[39m     output = to_pil_image(output, mode=img.mode)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UPM/Complex Data/FinalProject/scripts/.venv/lib/python3.13/site-packages/torchvision/transforms/_functional_tensor.py:761\u001b[39m, in \u001b[36mgaussian_blur\u001b[39m\u001b[34m(img, kernel_size, sigma)\u001b[39m\n\u001b[32m    759\u001b[39m padding = [kernel_size[\u001b[32m0\u001b[39m] // \u001b[32m2\u001b[39m, kernel_size[\u001b[32m0\u001b[39m] // \u001b[32m2\u001b[39m, kernel_size[\u001b[32m1\u001b[39m] // \u001b[32m2\u001b[39m, kernel_size[\u001b[32m1\u001b[39m] // \u001b[32m2\u001b[39m]\n\u001b[32m    760\u001b[39m img = torch_pad(img, padding, mode=\u001b[33m\"\u001b[39m\u001b[33mreflect\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m761\u001b[39m img = \u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    763\u001b[39m img = _cast_squeeze_out(img, need_cast, need_squeeze, out_dtype)\n\u001b[32m    764\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'lr': []}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc, _, _ = validate(model, val_loader, criterion)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "    print(f\"LR: {current_lr:.2e}\")\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), RESULTS_DIR / 'best_model.pth')\n",
    "        print(f\"‚úì Best model saved! (Val Acc: {val_acc:.2f}%)\")\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    if patience_counter >= early_stop_patience:\n",
    "        print(f\"\\n‚ö† Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Best Val Acc: {best_val_acc:.2f}%\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bbfded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training diagnostics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "axes[0, 0].plot(history['train_loss'], 'o-', label='Train')\n",
    "axes[0, 0].plot(history['val_loss'], 's-', label='Val')\n",
    "axes[0, 0].set_title('Loss', fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "axes[0, 1].plot(history['train_acc'], 'o-', label='Train')\n",
    "axes[0, 1].plot(history['val_acc'], 's-', label='Val')\n",
    "axes[0, 1].set_title('Accuracy', fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "axes[1, 0].plot(history['lr'], 'o-', color='red')\n",
    "axes[1, 0].set_title('Learning Rate', fontweight='bold')\n",
    "axes[1, 0].set_yscale('log')\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "diff = np.array(history['train_acc']) - np.array(history['val_acc'])\n",
    "axes[1, 1].plot(diff, 'o-', color='purple')\n",
    "axes[1, 1].axhline(0, color='k', linestyle='--')\n",
    "axes[1, 1].axhline(5, color='r', linestyle='--', label='5% threshold')\n",
    "axes[1, 1].set_title('Overfitting Analysis (Train-Val)', fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle('Training Diagnostics', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / '02_training.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Diagnosis\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING DIAGNOSIS\")\n",
    "print(\"=\"*70)\n",
    "final_gap = history['train_acc'][-1] - history['val_acc'][-1]\n",
    "if final_gap > 10:\n",
    "    print(\"‚ö† Overfitting detected (gap > 10%)\")\n",
    "elif final_gap > 5:\n",
    "    print(\"‚ö† Mild overfitting (gap 5-10%)\")\n",
    "else:\n",
    "    print(\"‚úì Well-generalized (gap < 5%)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e55a73",
   "metadata": {},
   "source": [
    "## **Requirement 4.4: Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32c0303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model and evaluate\n",
    "model.load_state_dict(torch.load(RESULTS_DIR / 'best_model.pth'))\n",
    "test_loss, test_acc, test_preds, test_labels = validate(model, test_loader, criterion)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST SET EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbffa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(\"\\nCLASSIFICATION REPORT\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(test_labels, test_preds, target_names=class_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d007fde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('True', fontweight='bold')\n",
    "plt.xlabel('Predicted', fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / '03_confusion_matrix.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPer-Class Accuracy:\")\n",
    "for i, name in enumerate(class_names):\n",
    "    acc = 100 * cm[i, i] / cm[i].sum()\n",
    "    print(f\"  {name:<25}: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46e53a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curves\n",
    "model.eval()\n",
    "all_probs, all_true = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        probs = torch.softmax(outputs, 1)\n",
    "        all_probs.append(probs.cpu().numpy())\n",
    "        all_true.append(labels.numpy())\n",
    "\n",
    "all_probs = np.vstack(all_probs)\n",
    "all_true = np.concatenate(all_true)\n",
    "\n",
    "y_bin = label_binarize(all_true, classes=range(len(class_names)))\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "auc_scores = []\n",
    "\n",
    "for i, name in enumerate(class_names):\n",
    "    fpr, tpr, _ = roc_curve(y_bin[:, i], all_probs[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    auc_scores.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{name} (AUC={roc_auc:.4f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlabel('False Positive Rate', fontweight='bold')\n",
    "plt.ylabel('True Positive Rate', fontweight='bold')\n",
    "plt.title('ROC Curves', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / '04_roc.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nMean AUC: {np.mean(auc_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f51832",
   "metadata": {},
   "source": [
    "## Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f31cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {\n",
    "    'Task': 'Multi-class Classification',\n",
    "    'Classes': len(class_names),\n",
    "    'Architecture': 'ResNet50 (Transfer Learning)',\n",
    "    'Test Accuracy': f'{test_acc:.2f}%',\n",
    "    'Mean AUC': f'{np.mean(auc_scores):.4f}',\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "for k, v in summary.items():\n",
    "    print(f\"{k:<20}: {v}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n‚úÖ PROJECT REQUIREMENTS COMPLETED:\")\n",
    "print(\"  4.1 Task Selection ‚úì\")\n",
    "print(\"  4.2 Data Preparation ‚úì\")\n",
    "print(\"  4.3 Architecture & Training ‚úì\")\n",
    "print(\"  4.4 Model Evaluation ‚úì\")\n",
    "\n",
    "print(f\"\\nüìÅ Results saved to: {RESULTS_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

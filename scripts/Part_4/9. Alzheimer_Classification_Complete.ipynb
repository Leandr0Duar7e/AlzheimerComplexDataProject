{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1fd9fdf",
   "metadata": {},
   "source": [
    "## üìã Project Requirements Checklist\n",
    "\n",
    "‚úÖ **4.1 Task Selection**: Classification task justified by categorical labels  \n",
    "‚úÖ **4.2 Data Preparation**: Train/test split with preprocessing  \n",
    "‚úÖ **4.3 Architecture & Training**: ResNet50 with training diagnosis  \n",
    "‚úÖ **4.4 Model Evaluation**: Comprehensive metrics on test set  \n",
    "\n",
    "**Dataset**: Alzheimer's 4-class MRI  \n",
    "**Task**: Multi-class Image Classification  \n",
    "**Model**: ResNet50 (Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40dcb424",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 1. SETUP\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moptim\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# 1. SETUP\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"‚úì Device: {device}\")\n",
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = Path(r\"c:\\Users\\ottav\\OneDrive - Politecnico di Milano\\Desktop\\ComplexData\\AlzheimerComplexDataProject\")\n",
    "DATA_DIR = PROJECT_ROOT / \"Data\" / \"Alzheimer_MRI\"\n",
    "RESULTS_DIR = PROJECT_ROOT / \"Results\" / \"MRI_Classification\"\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"‚úì Results: {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211e1557",
   "metadata": {},
   "source": [
    "## **Requirement 4.1: Task Selection**\n",
    "\n",
    "Download from: https://www.kaggle.com/datasets/tourist55/alzheimers-dataset-4-class-of-images\n",
    "\n",
    "Expected structure:\n",
    "```\n",
    "Data/Alzheimer_MRI/\n",
    "‚îú‚îÄ‚îÄ train/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ MildDemented/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ ModerateDemented/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ NonDemented/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ VeryMildDemented/\n",
    "‚îî‚îÄ‚îÄ test/\n",
    "    ‚îî‚îÄ‚îÄ [same structure]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec882f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dataset\n",
    "train_dir = DATA_DIR / \"train\"\n",
    "test_dir = DATA_DIR / \"test\"\n",
    "\n",
    "if train_dir.exists():\n",
    "    classes = sorted([d.name for d in train_dir.iterdir() if d.is_dir()])\n",
    "    print(\"=\"*70)\n",
    "    print(\"TASK SELECTION ANALYSIS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Dataset Type: Labeled image folders\")\n",
    "    print(f\"Classes: {classes}\")\n",
    "    print(f\"Number: {len(classes)}\")\n",
    "    print(f\"\\nüéØ TASK: Multi-class Classification\")\n",
    "    print(f\"Rationale: Categorical labels ‚Üí Classification task\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"‚ùå Dataset not found! Please download first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da72f0e",
   "metadata": {},
   "source": [
    "## **Requirement 4.2: Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40376c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset statistics\n",
    "def count_images(directory):\n",
    "    stats = {}\n",
    "    for class_dir in directory.iterdir():\n",
    "        if class_dir.is_dir():\n",
    "            imgs = list(class_dir.glob('*.jpg')) + list(class_dir.glob('*.png'))\n",
    "            stats[class_dir.name] = len(imgs)\n",
    "    return stats\n",
    "\n",
    "train_stats = count_images(train_dir)\n",
    "test_stats = count_images(test_dir)\n",
    "\n",
    "print(\"\\nüìà DATASET STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Class':<25} {'Train':<10} {'Test':<10} {'Total':<10}\")\n",
    "print(\"-\"*70)\n",
    "for cls in sorted(train_stats.keys()):\n",
    "    tr, te = train_stats[cls], test_stats[cls]\n",
    "    print(f\"{cls:<25} {tr:<10} {te:<10} {tr+te:<10}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "ax1.bar(train_stats.keys(), train_stats.values(), color='steelblue')\n",
    "ax1.set_title('Training Set', fontweight='bold')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax2.bar(test_stats.keys(), test_stats.values(), color='coral')\n",
    "ax2.set_title('Test Set', fontweight='bold')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / '01_distribution.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46839e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing with noise reduction\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.GaussianBlur(3, sigma=(0.1, 2.0)),  # Noise reduction\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "print(\"‚úì Preprocessing defined:\")\n",
    "print(\"  ‚Ä¢ Noise reduction: Gaussian blur\")\n",
    "print(\"  ‚Ä¢ Augmentation: Flip, rotate, color jitter\")\n",
    "print(\"  ‚Ä¢ Normalization: ImageNet statistics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a331335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_full = datasets.ImageFolder(train_dir, transform=data_transforms['train'])\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n",
    "\n",
    "# Split train ‚Üí train + val (80-20)\n",
    "train_size = int(0.8 * len(train_full))\n",
    "val_size = len(train_full) - train_size\n",
    "train_dataset, val_dataset = random_split(train_full, [train_size, val_size])\n",
    "val_dataset.dataset.transform = data_transforms['test']\n",
    "\n",
    "class_names = train_full.classes\n",
    "print(f\"\\n‚úì Splits: Train={len(train_dataset)}, Val={len(val_dataset)}, Test={len(test_dataset)}\")\n",
    "print(f\"‚úì Classes: {class_names}\")\n",
    "\n",
    "# DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13015f85",
   "metadata": {},
   "source": [
    "## **Requirement 4.3: Architecture Selection & Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d4398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "class AlzheimerClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        \n",
    "        # Freeze backbone\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Custom classifier\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "model = AlzheimerClassifier(len(class_names)).to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL ARCHITECTURE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Base: ResNet50 (ImageNet pretrained)\")\n",
    "print(f\"Total params: {total_params:,}\")\n",
    "print(f\"Trainable: {trainable:,}\")\n",
    "print(f\"Frozen: {total_params-trainable:,}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991253d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "num_epochs = 25\n",
    "early_stop_patience = 7\n",
    "best_val_acc = 0.0\n",
    "patience_counter = 0\n",
    "\n",
    "print(\"‚úì Configuration:\")\n",
    "print(f\"  ‚Ä¢ Epochs: {num_epochs}\")\n",
    "print(f\"  ‚Ä¢ Optimizer: Adam (lr=0.001, wd=1e-4)\")\n",
    "print(f\"  ‚Ä¢ Scheduler: ReduceLROnPlateau\")\n",
    "print(f\"  ‚Ä¢ Early stopping: {early_stop_patience} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce197c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training functions\n",
    "def train_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc='Train', leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "    \n",
    "    return running_loss / total, 100. * correct / total\n",
    "\n",
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc='Val', leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, preds = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return running_loss / total, 100. * correct / total, all_preds, all_labels\n",
    "\n",
    "print(\"‚úì Training functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf63e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'lr': []}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc, _, _ = validate(model, val_loader, criterion)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "    print(f\"LR: {current_lr:.2e}\")\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), RESULTS_DIR / 'best_model.pth')\n",
    "        print(f\"‚úì Best model saved! (Val Acc: {val_acc:.2f}%)\")\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    if patience_counter >= early_stop_patience:\n",
    "        print(f\"\\n‚ö† Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Best Val Acc: {best_val_acc:.2f}%\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bbfded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training diagnostics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "axes[0, 0].plot(history['train_loss'], 'o-', label='Train')\n",
    "axes[0, 0].plot(history['val_loss'], 's-', label='Val')\n",
    "axes[0, 0].set_title('Loss', fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "axes[0, 1].plot(history['train_acc'], 'o-', label='Train')\n",
    "axes[0, 1].plot(history['val_acc'], 's-', label='Val')\n",
    "axes[0, 1].set_title('Accuracy', fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "axes[1, 0].plot(history['lr'], 'o-', color='red')\n",
    "axes[1, 0].set_title('Learning Rate', fontweight='bold')\n",
    "axes[1, 0].set_yscale('log')\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "diff = np.array(history['train_acc']) - np.array(history['val_acc'])\n",
    "axes[1, 1].plot(diff, 'o-', color='purple')\n",
    "axes[1, 1].axhline(0, color='k', linestyle='--')\n",
    "axes[1, 1].axhline(5, color='r', linestyle='--', label='5% threshold')\n",
    "axes[1, 1].set_title('Overfitting Analysis (Train-Val)', fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle('Training Diagnostics', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / '02_training.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Diagnosis\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING DIAGNOSIS\")\n",
    "print(\"=\"*70)\n",
    "final_gap = history['train_acc'][-1] - history['val_acc'][-1]\n",
    "if final_gap > 10:\n",
    "    print(\"‚ö† Overfitting detected (gap > 10%)\")\n",
    "elif final_gap > 5:\n",
    "    print(\"‚ö† Mild overfitting (gap 5-10%)\")\n",
    "else:\n",
    "    print(\"‚úì Well-generalized (gap < 5%)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e55a73",
   "metadata": {},
   "source": [
    "## **Requirement 4.4: Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32c0303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model and evaluate\n",
    "model.load_state_dict(torch.load(RESULTS_DIR / 'best_model.pth'))\n",
    "test_loss, test_acc, test_preds, test_labels = validate(model, test_loader, criterion)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST SET EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbffa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(\"\\nCLASSIFICATION REPORT\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(test_labels, test_preds, target_names=class_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d007fde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('True', fontweight='bold')\n",
    "plt.xlabel('Predicted', fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / '03_confusion_matrix.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPer-Class Accuracy:\")\n",
    "for i, name in enumerate(class_names):\n",
    "    acc = 100 * cm[i, i] / cm[i].sum()\n",
    "    print(f\"  {name:<25}: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46e53a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curves\n",
    "model.eval()\n",
    "all_probs, all_true = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        probs = torch.softmax(outputs, 1)\n",
    "        all_probs.append(probs.cpu().numpy())\n",
    "        all_true.append(labels.numpy())\n",
    "\n",
    "all_probs = np.vstack(all_probs)\n",
    "all_true = np.concatenate(all_true)\n",
    "\n",
    "y_bin = label_binarize(all_true, classes=range(len(class_names)))\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "auc_scores = []\n",
    "\n",
    "for i, name in enumerate(class_names):\n",
    "    fpr, tpr, _ = roc_curve(y_bin[:, i], all_probs[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    auc_scores.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{name} (AUC={roc_auc:.4f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlabel('False Positive Rate', fontweight='bold')\n",
    "plt.ylabel('True Positive Rate', fontweight='bold')\n",
    "plt.title('ROC Curves', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / '04_roc.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nMean AUC: {np.mean(auc_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f51832",
   "metadata": {},
   "source": [
    "## Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f31cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {\n",
    "    'Task': 'Multi-class Classification',\n",
    "    'Classes': len(class_names),\n",
    "    'Architecture': 'ResNet50 (Transfer Learning)',\n",
    "    'Test Accuracy': f'{test_acc:.2f}%',\n",
    "    'Mean AUC': f'{np.mean(auc_scores):.4f}',\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "for k, v in summary.items():\n",
    "    print(f\"{k:<20}: {v}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n‚úÖ PROJECT REQUIREMENTS COMPLETED:\")\n",
    "print(\"  4.1 Task Selection ‚úì\")\n",
    "print(\"  4.2 Data Preparation ‚úì\")\n",
    "print(\"  4.3 Architecture & Training ‚úì\")\n",
    "print(\"  4.4 Model Evaluation ‚úì\")\n",
    "\n",
    "print(f\"\\nüìÅ Results saved to: {RESULTS_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Recommender-Systems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

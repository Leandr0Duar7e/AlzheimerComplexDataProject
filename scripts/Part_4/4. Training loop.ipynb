{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNP5vmv24DGLYdQV0ZlgoAP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Training a Neural Network\n","Prerequisite Code: Define a Dataset, DataLoader, and Model."],"metadata":{"id":"EmoZnMbUOQXw"}},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dS005GiXKMtW","executionInfo":{"status":"ok","timestamp":1761041219478,"user_tz":-120,"elapsed":3230,"user":{"displayName":"David Gómez","userId":"13753498048077981965"}},"outputId":"1d563009-ad71-41c0-87d8-d602663623cd"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 9.91M/9.91M [00:00<00:00, 18.0MB/s]\n","100%|██████████| 28.9k/28.9k [00:00<00:00, 484kB/s]\n","100%|██████████| 1.65M/1.65M [00:00<00:00, 4.49MB/s]\n","100%|██████████| 4.54k/4.54k [00:00<00:00, 7.89MB/s]\n"]}],"source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","\n","training_data = datasets.MNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=ToTensor()\n",")\n","\n","test_data = datasets.MNIST(\n","    root=\"data\",\n","    train=False,\n","    download=True,\n","    transform=ToTensor()\n",")\n","\n","train_dataloader = DataLoader(training_data, batch_size=64)\n","test_dataloader = DataLoader(test_data, batch_size=64)\n","\n","class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10),\n","        )\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits\n","\n","model = NeuralNetwork()"]},{"cell_type":"markdown","source":["Define training hyperparameters: # of epochs, batch size, and optimizer learning rate."],"metadata":{"id":"tv81D9FbOgzU"}},{"cell_type":"code","source":["learning_rate = 1e-3\n","batch_size = 64\n","epochs = 5"],"metadata":{"id":"rtyLYOf8KYVt","executionInfo":{"status":"ok","timestamp":1761041219482,"user_tz":-120,"elapsed":2,"user":{"displayName":"David Gómez","userId":"13753498048077981965"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["Define training loop and testing loop."],"metadata":{"id":"lQyoFnW_Ot_N"}},{"cell_type":"code","source":["def train_loop(dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset)\n","    # Set the model to training mode - important for batch normalization and dropout layers\n","    # Unnecessary in this situation but added for best practices\n","    model.train()\n","    for batch, (X, y) in enumerate(dataloader):\n","        # Compute prediction and loss\n","        pred = model(X)\n","        loss = loss_fn(pred, y)\n","\n","        # Backpropagation\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","        if batch % 100 == 0:\n","            loss, current = loss.item(), batch * batch_size + len(X)\n","            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n","\n","\n","def test_loop(dataloader, model, loss_fn):\n","    # Set the model to evaluation mode - important for batch normalization and dropout layers\n","    # Unnecessary in this situation but added for best practices\n","    model.eval()\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    test_loss, correct = 0, 0\n","\n","    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n","    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n","    with torch.no_grad():\n","        for X, y in dataloader:\n","            pred = model(X)\n","            test_loss += loss_fn(pred, y).item()\n","            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","\n","    test_loss /= num_batches\n","    correct /= size\n","    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"],"metadata":{"id":"lVqFKCsoLeYw","executionInfo":{"status":"ok","timestamp":1761041219489,"user_tz":-120,"elapsed":2,"user":{"displayName":"David Gómez","userId":"13753498048077981965"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["Define the loss function and optimizer"],"metadata":{"id":"SBDG0xPsOyEq"}},{"cell_type":"code","source":["loss_fn = nn.CrossEntropyLoss()\n","loss_fn = nn.BCEWithLogitsLoss()\n","loss_fn = nn.MSELoss()\n","\n","\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"],"metadata":{"id":"4PpqXkcTOxjC","executionInfo":{"status":"ok","timestamp":1761041219500,"user_tz":-120,"elapsed":2,"user":{"displayName":"David Gómez","userId":"13753498048077981965"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["Train the model"],"metadata":{"id":"PxjwJBhcO_m8"}},{"cell_type":"code","source":["epochs = 1\n","for t in range(epochs):\n","    print(f\"Epoch {t+1}\\n-------------------------------\")\n","    train_loop(train_dataloader, model, loss_fn, optimizer)\n","    test_loop(test_dataloader, model, loss_fn)\n","print(\"Done!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lZACKCgrLgIo","executionInfo":{"status":"ok","timestamp":1761041234171,"user_tz":-120,"elapsed":14669,"user":{"displayName":"David Gómez","userId":"13753498048077981965"}},"outputId":"49da1638-d9f7-426a-bc59-b40a30bb4eb0"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","-------------------------------\n","loss: 2.299727  [   64/60000]\n","loss: 2.298325  [ 6464/60000]\n","loss: 2.296356  [12864/60000]\n","loss: 2.282496  [19264/60000]\n","loss: 2.292631  [25664/60000]\n","loss: 2.281569  [32064/60000]\n","loss: 2.266590  [38464/60000]\n","loss: 2.279882  [44864/60000]\n","loss: 2.260869  [51264/60000]\n","loss: 2.246347  [57664/60000]\n","Test Error: \n"," Accuracy: 47.1%, Avg loss: 2.253135 \n","\n","Done!\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"7OEk-BkdPCA0","executionInfo":{"status":"ok","timestamp":1761041234186,"user_tz":-120,"elapsed":10,"user":{"displayName":"David Gómez","userId":"13753498048077981965"}}},"execution_count":12,"outputs":[]}]}
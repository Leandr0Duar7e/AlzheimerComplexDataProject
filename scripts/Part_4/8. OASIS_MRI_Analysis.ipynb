{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c13024f",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Data Download\n",
    "\n",
    "First, install the Kaggle API and download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e05f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install kaggle pillow torch torchvision scikit-learn pandas numpy matplotlib seaborn\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Set up paths\n",
    "PROJECT_ROOT = Path(r\"c:\\Users\\ottav\\OneDrive - Politecnico di Milano\\Desktop\\ComplexData\\AlzheimerComplexDataProject\")\n",
    "DATA_DIR = PROJECT_ROOT / \"Data\" / \"OASIS\"\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d317bb1",
   "metadata": {},
   "source": [
    "### Download Dataset from Kaggle\n",
    "\n",
    "**Manual steps**:\n",
    "1. Go to https://www.kaggle.com/datasets/ninadaithal/imagesoasis/data\n",
    "2. Click \"Download\" and extract to the `Data/OASIS/` directory\n",
    "3. The structure should be:\n",
    "   ```\n",
    "   Data/OASIS/\n",
    "   ├── oasis_cross-sectional.csv  (metadata)\n",
    "   └── [MRI image folders]/\n",
    "   ```\n",
    "\n",
    "**Or use Kaggle API**:\n",
    "```python\n",
    "# Make sure you have ~/.kaggle/kaggle.json configured\n",
    "# !kaggle datasets download -d ninadaithal/imagesoasis -p Data/OASIS --unzip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d60ab8",
   "metadata": {},
   "source": [
    "## Step 2: Exploratory Data Analysis (EDA)\n",
    "\n",
    "Load and explore the metadata to understand the dataset structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fb420f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "csv_path = DATA_DIR / \"oasis_cross-sectional.csv\"\n",
    "\n",
    "# If you haven't downloaded yet, this will fail - follow Step 1 first\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumn names:\\n{df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c838a1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset statistics\n",
    "print(\"Dataset Information:\")\n",
    "print(df.info())\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Statistical Summary:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7217cd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Distribution of key variables\n",
    "print(f\"\\nCDR (Clinical Dementia Rating) distribution:\")\n",
    "print(df['CDR'].value_counts().sort_index())\n",
    "\n",
    "print(f\"\\nGender distribution:\")\n",
    "print(df['M/F'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb099470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize key distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# CDR distribution\n",
    "df['CDR'].value_counts().sort_index().plot(kind='bar', ax=axes[0, 0], color='steelblue')\n",
    "axes[0, 0].set_title('Clinical Dementia Rating (CDR) Distribution')\n",
    "axes[0, 0].set_xlabel('CDR Score')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "\n",
    "# Age distribution\n",
    "df['Age'].hist(bins=20, ax=axes[0, 1], color='coral', edgecolor='black')\n",
    "axes[0, 1].set_title('Age Distribution')\n",
    "axes[0, 1].set_xlabel('Age')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# MMSE distribution (if available)\n",
    "if 'MMSE' in df.columns:\n",
    "    df['MMSE'].dropna().hist(bins=15, ax=axes[1, 0], color='green', alpha=0.7, edgecolor='black')\n",
    "    axes[1, 0].set_title('MMSE Score Distribution')\n",
    "    axes[1, 0].set_xlabel('MMSE Score')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "# CDR by Gender\n",
    "if 'M/F' in df.columns:\n",
    "    pd.crosstab(df['M/F'], df['CDR']).plot(kind='bar', ax=axes[1, 1], color=['lightblue', 'pink'])\n",
    "    axes[1, 1].set_title('CDR Distribution by Gender')\n",
    "    axes[1, 1].set_xlabel('Gender')\n",
    "    axes[1, 1].set_ylabel('Count')\n",
    "    axes[1, 1].legend(title='CDR', bbox_to_anchor=(1.05, 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024db461",
   "metadata": {},
   "source": [
    "## Step 3: Create Classification Labels\n",
    "\n",
    "Create binary labels for dementia classification:\n",
    "- **0 (Non-Demented)**: CDR = 0\n",
    "- **1 (Demented)**: CDR > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecfd337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary classification labels\n",
    "df['Demented'] = (df['CDR'] > 0).astype(int)\n",
    "\n",
    "print(\"Class distribution:\")\n",
    "print(df['Demented'].value_counts())\n",
    "print(f\"\\nClass balance: {df['Demented'].value_counts(normalize=True)}\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(8, 5))\n",
    "df['Demented'].value_counts().plot(kind='bar', color=['green', 'red'], alpha=0.7)\n",
    "plt.title('Dementia Classification Distribution')\n",
    "plt.xlabel('Class (0=Non-Demented, 1=Demented)')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd10195c",
   "metadata": {},
   "source": [
    "## Step 4: Custom PyTorch Dataset\n",
    "\n",
    "Create a custom dataset class to load MRI images and their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e293e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "class OASISDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset for OASIS MRI images\n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe, img_dir, transform=None, task='classification'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe: pandas DataFrame with metadata\n",
    "            img_dir: Directory containing MRI images\n",
    "            transform: Optional transform to be applied on images\n",
    "            task: 'classification' or 'regression'\n",
    "        \"\"\"\n",
    "        self.df = dataframe.copy()\n",
    "        self.img_dir = Path(img_dir)\n",
    "        self.transform = transform\n",
    "        self.task = task\n",
    "        \n",
    "        # Find image paths\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for idx, row in self.df.iterrows():\n",
    "            # Adjust this based on actual folder structure\n",
    "            subject_id = row['ID']\n",
    "            # Look for images in subject folder\n",
    "            subject_folder = self.img_dir / subject_id\n",
    "            \n",
    "            if subject_folder.exists():\n",
    "                # Get first MRI image (you may want to select specific slices)\n",
    "                img_files = list(subject_folder.glob('*.gif')) + list(subject_folder.glob('*.jpg')) + list(subject_folder.glob('*.png'))\n",
    "                \n",
    "                if img_files:\n",
    "                    self.image_paths.append(img_files[0])\n",
    "                    \n",
    "                    if self.task == 'classification':\n",
    "                        self.labels.append(row['Demented'])\n",
    "                    else:  # regression\n",
    "                        self.labels.append(row['CDR'])\n",
    "        \n",
    "        print(f\"Found {len(self.image_paths)} images\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Get label\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.task == 'classification':\n",
    "            label = torch.tensor(label, dtype=torch.long)\n",
    "        else:  # regression\n",
    "            label = torch.tensor(label, dtype=torch.float32)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744f0eed",
   "metadata": {},
   "source": [
    "## Step 5: Data Preprocessing and Augmentation\n",
    "\n",
    "Define transforms for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46427ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Image preprocessing\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                       std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                       std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"Transforms defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0284395",
   "metadata": {},
   "source": [
    "## Step 6: Train-Test Split\n",
    "\n",
    "Split the data into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf96b896",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data (stratified for classification)\n",
    "train_df, val_df = train_test_split(\n",
    "    df, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=df['Demented']  # Ensure balanced split\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(train_df)}\")\n",
    "print(f\"Validation set size: {len(val_df)}\")\n",
    "\n",
    "print(f\"\\nTraining set class distribution:\")\n",
    "print(train_df['Demented'].value_counts())\n",
    "print(f\"\\nValidation set class distribution:\")\n",
    "print(val_df['Demented'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003f4fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = OASISDataset(\n",
    "    train_df, \n",
    "    img_dir=DATA_DIR,  # Adjust based on actual structure\n",
    "    transform=train_transform,\n",
    "    task='classification'\n",
    ")\n",
    "\n",
    "val_dataset = OASISDataset(\n",
    "    val_df, \n",
    "    img_dir=DATA_DIR,\n",
    "    transform=val_transform,\n",
    "    task='classification'\n",
    ")\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=16, \n",
    "    shuffle=True,\n",
    "    num_workers=0  # Set to 0 for Windows compatibility\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=16, \n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(f\"Train loader batches: {len(train_loader)}\")\n",
    "print(f\"Val loader batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d87283",
   "metadata": {},
   "source": [
    "## Step 7: Model Architecture\n",
    "\n",
    "Choose a pre-trained model and adapt it for our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7f1323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "def create_classification_model(num_classes=2, pretrained=True):\n",
    "    \"\"\"\n",
    "    Create ResNet50 model for classification\n",
    "    \"\"\"\n",
    "    model = models.resnet50(pretrained=pretrained)\n",
    "    \n",
    "    # Freeze early layers (optional)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Replace final layer\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(num_ftrs, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(512, num_classes)\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_regression_model(pretrained=True):\n",
    "    \"\"\"\n",
    "    Create ResNet50 model for regression (CDR prediction)\n",
    "    \"\"\"\n",
    "    model = models.resnet50(pretrained=pretrained)\n",
    "    \n",
    "    # Freeze early layers\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Replace final layer for regression\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(num_ftrs, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(512, 1)  # Single output for regression\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = create_classification_model(num_classes=2, pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"\\nModel architecture:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79b7dd6",
   "metadata": {},
   "source": [
    "## Step 8: Training Setup\n",
    "\n",
    "Define loss function, optimizer, and training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98826d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification setup\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 20\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "print(\"Training setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406aaccb",
   "metadata": {},
   "source": [
    "## Step 9: Training and Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016f79c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    \"\"\"Validate the model\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "print(\"Training functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7b21b8",
   "metadata": {},
   "source": [
    "## Step 10: Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154e6ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [], 'train_acc': [],\n",
    "    'val_loss': [], 'val_acc': []\n",
    "}\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Print progress\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"  Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), DATA_DIR / 'best_model.pth')\n",
    "        print(f\"  ✓ Saved best model (val_loss: {val_loss:.4f})\")\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf6d6b9",
   "metadata": {},
   "source": [
    "## Step 11: Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ea0583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss curves\n",
    "ax1.plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "ax1.plot(history['val_loss'], label='Val Loss', marker='s')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy curves\n",
    "ax2.plot(history['train_acc'], label='Train Acc', marker='o')\n",
    "ax2.plot(history['val_acc'], label='Val Acc', marker='s')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('Training and Validation Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(DATA_DIR / 'training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916c2382",
   "metadata": {},
   "source": [
    "## Step 12: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93702a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load(DATA_DIR / 'best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Collect predictions\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        _, preds = outputs.max(1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "        all_probs.extend(probs[:, 1].cpu().numpy())  # Probability of class 1\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=['Non-Demented', 'Demented']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Non-Demented', 'Demented'],\n",
    "            yticklabels=['Non-Demented', 'Demented'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.savefig(DATA_DIR / 'confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "auc_score = roc_auc_score(all_labels, all_probs)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, linewidth=2, label=f'AUC = {auc_score:.3f}')\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Dementia Classification')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(DATA_DIR / 'roc_curve.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af17a90f",
   "metadata": {},
   "source": [
    "## Next Steps & Variations\n",
    "\n",
    "### For Regression Task (Predicting CDR Score):\n",
    "1. Change `task='regression'` in dataset creation\n",
    "2. Use `create_regression_model()`\n",
    "3. Use `nn.MSELoss()` as criterion\n",
    "4. Evaluate with MAE, RMSE, R² metrics\n",
    "\n",
    "### Model Improvements:\n",
    "- Try different architectures (VGG16, EfficientNet, Vision Transformer)\n",
    "- Use 3D CNNs for volumetric MRI data\n",
    "- Implement attention mechanisms\n",
    "- Ensemble multiple models\n",
    "\n",
    "### Data Improvements:\n",
    "- Use multiple MRI slices per subject\n",
    "- Add clinical features (age, gender, education) as additional inputs\n",
    "- Apply medical image preprocessing (skull stripping, intensity normalization)\n",
    "- Use data augmentation specific to medical images\n",
    "\n",
    "### Advanced Techniques:\n",
    "- Cross-validation for robust evaluation\n",
    "- Class weighting for imbalanced data\n",
    "- Transfer learning from medical image datasets\n",
    "- Explainability with GradCAM or SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc6d52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final results summary\n",
    "results_summary = {\n",
    "    'Best Val Loss': best_val_loss,\n",
    "    'Final Val Accuracy': history['val_acc'][-1],\n",
    "    'AUC Score': auc_score,\n",
    "    'Training Epochs': num_epochs\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "for key, value in results_summary.items():\n",
    "    print(f\"{key}: {value:.4f}\" if isinstance(value, float) else f\"{key}: {value}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightfm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
